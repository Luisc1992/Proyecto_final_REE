{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f983fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda_hackaboss\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda_hackaboss\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: sqlalchemy in d:\\anaconda_hackaboss\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: psycopg2-binary in d:\\anaconda_hackaboss\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda_hackaboss\\lib\\site-packages (1.5.1)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: joblib in d:\\anaconda_hackaboss\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda_hackaboss\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda_hackaboss\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda_hackaboss\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\anaconda_hackaboss\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda_hackaboss\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda_hackaboss\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda_hackaboss\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda_hackaboss\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.5 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy sqlalchemy psycopg2-binary scikit-learn lightgbm joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import timedelta\n",
    "\n",
    "#DB\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# ML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"proyectohabreee.cv4ea0syasip.eu-north-1.rds.amazonaws.com\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"postgres\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\", \"proyectohabree123\")\n",
    "TABLE_NAME = \"demanda_ree\"\n",
    "\n",
    "# Paths\n",
    "MODEL_PATH = \"lgb_demand_model.joblib\"\n",
    "FEATURES_PATH = \"features_cols.txt\"\n",
    "\n",
    "# ---------------------------\n",
    "# 1) EXTRAER DATOS\n",
    "# ---------------------------\n",
    "def load_data_from_rds(limit_rows=None, date_from=None, date_to=None):\n",
    "    \"\"\"\n",
    "    Conecta a la BBDD y devuelve un DataFrame con columnas: id, fecha, demanda_mw\n",
    "    Opcional: limit_rows para desarrollo local.\n",
    "    \"\"\"\n",
    "    conn_str = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "    engine = create_engine(conn_str, connect_args={\"connect_timeout\": 10})\n",
    "    query = f\"SELECT id, fecha, demanda_mw FROM {TABLE_NAME} ORDER BY fecha ASC\" \n",
    "    if limit_rows:\n",
    "        query += f\" LIMIT {limit_rows}\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "741763e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 2) PREPROCESS / FEATURE ENGINEERING\n",
    "# ---------------------------\n",
    "def preprocess_and_features(df):\n",
    "    \"\"\"\n",
    "    - Convierte fecha a datetime y ordena.\n",
    "    - Crea features temporales y lags/rolling.\n",
    "    - Devuelve DataFrame listo para modelado.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['fecha'] = pd.to_datetime(df['fecha']).dt.date\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    df = df.sort_values('fecha').drop_duplicates(subset='fecha').reset_index(drop=True)\n",
    "          \n",
    "    # Features temporales\n",
    "    df['dayofweek'] = df['fecha'].dt.dayofweek\n",
    "    df['month'] = df['fecha'].dt.month\n",
    "    df['is_weekend'] = df['dayofweek'].isin([5,6]).astype(int)\n",
    "    \n",
    "    # Crea lags: 1, 7, 14, 30 (ayer, una semana antes, dos semanas antes, un mes antes)\n",
    "    lags = [1, 7, 14, 30]  # personalizable\n",
    "    for l in lags:\n",
    "        df[f'lag_{l}'] = df['demanda_mw'].shift(l)\n",
    "    \n",
    "    # rolling means\n",
    "    windows = [7, 14, 30]\n",
    "    for w in windows:\n",
    "        df[f'roll_mean_{w}'] = df['demanda_mw'].shift(1).rolling(window=w, min_periods=1).mean()\n",
    "        df[f'roll_std_{w}'] = df['demanda_mw'].shift(1).rolling(window=w, min_periods=1).std().fillna(0)\n",
    "    \n",
    "    # Drop initial rows with NaN from lags\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a14eb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 3) TRAIN / VALIDATION SPLIT (temporal)\n",
    "# ---------------------------\n",
    "def temporal_train_test_split(df, val_size_days=500, test_size_days=500):\n",
    "    \"\"\"\n",
    "    Divide en train/val/test en orden temporal.\n",
    "    val_size_days, test_size_days: cuánto reservar para validación y test (en días).\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    if n < (val_size_days + test_size_days + 10):\n",
    "        raise ValueError(\"Muy pocos datos para dividir en train/val/test.\")\n",
    "\n",
    "    train_end = n - val_size_days - test_size_days\n",
    "    val_end = n - test_size_days\n",
    "\n",
    "    train = df.iloc[:train_end].copy()\n",
    "    val = df.iloc[train_end:val_end].copy()\n",
    "    test = df.iloc[val_end:].copy()\n",
    "    \n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "695a638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 4) MODEL TRAIN\n",
    "# ---------------------------\n",
    "def train_lightgbm(train_df, val_df, features, target='demanda_mw', params=None):\n",
    "    train_data = lgb.Dataset(train_df[features], label=train_df[target])\n",
    "    val_data = lgb.Dataset(val_df[features], label=val_df[target])\n",
    "    default_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.005,\n",
    "        \"num_leaves\": 31,\n",
    "        \"n_estimators\": 1000,\n",
    "    }\n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "    gbm = lgb.train(default_params, \n",
    "                    train_data, \n",
    "                    valid_sets=[val_data],\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(stopping_rounds=50),\n",
    "                        lgb.log_evaluation(period=50)  # imprime cada 50 iteraciones\n",
    "                    ] \n",
    "    )\n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89fbe77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 5) EVALUATION\n",
    "# ---------------------------\n",
    "def evaluate_model(model, df, features, target='demanda_mw'):\n",
    "    preds = model.predict(df[features])\n",
    "    mae = mean_absolute_error(df[target], preds)\n",
    "    rmse = mean_squared_error(df[target], preds, squared=False)\n",
    "    mape = np.mean(np.abs((df[target] - preds) / (df[target] + 1e-9))) * 100\n",
    "    accuracy = 100 - mape\n",
    "    return {\"MAE: \": mae, \"RMSE: \": rmse, \"MAPE(%): \": mape, \"ACC (%): \": accuracy}, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0977340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 6) PREDICT FUTURE (horizon steps)\n",
    "# ---------------------------\n",
    "def predict_future(model, last_df, features, horizon=7):\n",
    "    \"\"\"\n",
    "    last_df: DataFrame with the latest rows including features (must include fecha and demanda_mw).\n",
    "    Devuelve DataFrame con predicciones para next `horizon` steps (assume hourly).\n",
    "    Procedimiento: iterativo, se genera features usando predicción anterior para lags.\n",
    "    \"\"\"\n",
    "    last_df = last_df.copy().sort_values('fecha').reset_index(drop=True)\n",
    "    preds = []\n",
    "    df_work = last_df.copy()\n",
    "\n",
    "    for step in range(horizon):\n",
    "        next_time = df_work['fecha'].iloc[-1] + pd.Timedelta(days=1)\n",
    "        row = {\"fecha\": next_time}\n",
    "        row['dayofweek'] = next_time.dayofweek\n",
    "        row['month'] = next_time.month\n",
    "        row['is_weekend'] = int(next_time.dayofweek in [5,6])\n",
    "        \n",
    "        # lags: tomar de df_work\n",
    "        for l in [1,7,14,30]:\n",
    "            if l <= len(df_work):\n",
    "                row[f'lag_{l}'] = df_work['demanda_mw'].iloc[-l]\n",
    "            else:\n",
    "                row[f'lag_{l}'] = np.nan\n",
    "\n",
    "        # rolling means/std using last values\n",
    "        for w in [7,14,30]:\n",
    "            vals = df_work['demanda_mw'].shift(1).iloc[-w:] if len(df_work) >= 1 else []\n",
    "            if len(vals) > 0:\n",
    "                row[f'roll_mean_{w}'] = float(vals.mean())\n",
    "                row[f'roll_std_{w}'] = float(vals.std()) if len(vals) > 1 else 0.0\n",
    "            else:\n",
    "                row[f'roll_mean_{w}'] = np.nan\n",
    "                row[f'roll_std_{w}'] = np.nan\n",
    "        \n",
    "        row_df = pd.DataFrame([row])\n",
    "        # fill NaNs with reasonable values (e.g., mean of each column from df_work)\n",
    "        for c in features:\n",
    "            if c not in row_df.columns:\n",
    "                row_df[c] = np.nan\n",
    "        \n",
    "        # align columns\n",
    "        row_df = row_df[features].fillna(df_work[features].mean())\n",
    "        pred = model.predict(row_df)[0]\n",
    "        \n",
    "        # append\n",
    "        new_row = {\"fecha\": next_time, \"demanda_mw\": pred}\n",
    "        preds.append(new_row)\n",
    "        # add to df_work for next iteration\n",
    "        df_work = pd.concat([df_work, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    return pd.DataFrame(preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0efec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros extraídos: 5384\n",
      "Registros tras preprocess: 5354\n",
      "Tamaños -> train: 4354 val: 500 test: 500\n",
      "Columnas disponibles: ['id', 'fecha', 'demanda_mw', 'dayofweek', 'month', 'is_weekend', 'lag_1', 'lag_7', 'lag_14', 'lag_30', 'roll_mean_7', 'roll_std_7', 'roll_mean_14', 'roll_std_14', 'roll_mean_30', 'roll_std_30']\n",
      "Features seleccionadas: ['dayofweek', 'month', 'is_weekend', 'lag_1', 'lag_7', 'lag_14', 'lag_30', 'roll_mean_7', 'roll_std_7', 'roll_mean_14', 'roll_std_14', 'roll_mean_30', 'roll_std_30']\n",
      "Tamaño TRAIN: (4354, 16)\n",
      "Tamaño VAL: (500, 16)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's rmse: 64201.4\n",
      "[100]\tvalid_0's rmse: 53571.8\n",
      "[150]\tvalid_0's rmse: 45851.6\n",
      "[200]\tvalid_0's rmse: 40100.5\n",
      "[250]\tvalid_0's rmse: 35775.4\n",
      "[300]\tvalid_0's rmse: 32755.8\n",
      "[350]\tvalid_0's rmse: 30308\n",
      "[400]\tvalid_0's rmse: 28683.3\n",
      "[450]\tvalid_0's rmse: 27618.5\n",
      "[500]\tvalid_0's rmse: 26797.8\n",
      "[550]\tvalid_0's rmse: 26182.2\n",
      "[600]\tvalid_0's rmse: 25741.6\n",
      "[650]\tvalid_0's rmse: 25421.8\n",
      "[700]\tvalid_0's rmse: 25172.9\n",
      "[750]\tvalid_0's rmse: 25002.4\n",
      "[800]\tvalid_0's rmse: 24888.3\n",
      "[850]\tvalid_0's rmse: 24830.9\n",
      "[900]\tvalid_0's rmse: 24780.4\n",
      "[950]\tvalid_0's rmse: 24737.7\n",
      "[1000]\tvalid_0's rmse: 24714.4\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 24714.4\n",
      "Modelo guardado en: lgb_demand_model.joblib\n",
      "Evaluación TRAIN:  {'MAE: ': 10530.88084940568, 'RMSE: ': 16355.043760492512, 'MAPE(%): ': 1.5084285494107907, 'ACC (%): ': 98.4915714505892}\n",
      "Evaluación VAL:  {'MAE: ': 16873.52662630677, 'RMSE: ': 24714.38875186006, 'MAPE(%): ': 2.5699305486012074, 'ACC (%): ': 97.4300694513988}\n",
      "Evaluación TEST:  {'MAE: ': 16351.932616483065, 'RMSE: ': 24112.41222527402, 'MAPE(%): ': 2.454652584241292, 'ACC (%): ': 97.54534741575871}\n",
      "Predicciones próximos 7 dias:\n",
      "       fecha     demanda_mw\n",
      "0 2025-09-27  618044.330198\n",
      "1 2025-09-28  713207.629138\n",
      "2 2025-09-29  708601.656628\n",
      "3 2025-09-30  706269.968864\n",
      "4 2025-10-01  703658.119307\n",
      "5 2025-10-02  685747.591048\n",
      "6 2025-10-03  645822.066432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA_HACKABOSS\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA_HACKABOSS\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "d:\\ANACONDA_HACKABOSS\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# MAIN FLOW\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # 1. Cargar\n",
    "    df = load_data_from_rds()\n",
    "    print(\"Registros extraídos:\", len(df))\n",
    "    \n",
    "    # 2. Preprocess\n",
    "    df_proc = preprocess_and_features(df)\n",
    "    print(\"Registros tras preprocess:\", len(df_proc))\n",
    "    \n",
    "    # 3. Split\n",
    "    train, val, test = temporal_train_test_split(df_proc)\n",
    "    print(\"Tamaños -> train:\", len(train), \"val:\", len(val), \"test:\", len(test))\n",
    "    \n",
    "    # 4. Features list\n",
    "    # Excluir columnas id, fecha, demanda_mw\n",
    "    excluded = ['id', 'fecha', 'demanda_mw']\n",
    "    features = [c for c in df_proc.columns if c not in excluded]\n",
    "\n",
    "    print(\"Columnas disponibles:\", df_proc.columns.tolist())\n",
    "    print(\"Features seleccionadas:\", features)\n",
    "    print(\"Tamaño TRAIN:\", train.shape)\n",
    "    print(\"Tamaño VAL:\", val.shape)\n",
    "    \n",
    "    # Guardar lista de features\n",
    "    with open(FEATURES_PATH, 'w') as f:\n",
    "        f.write(\"\\n\".join(features))\n",
    "    \n",
    "    # 5. Entrenar LightGBM\n",
    "    model = train_lightgbm(train, val, features)\n",
    "    \n",
    "    # guardar modelo\n",
    "    joblib.dump(model, MODEL_PATH)\n",
    "    print(\"Modelo guardado en:\", MODEL_PATH)\n",
    "    \n",
    "    # 6. Evaluar en train/val/test\n",
    "    print(\"Evaluación TRAIN: \", evaluate_model(model, train, features)[0])\n",
    "    print(\"Evaluación VAL: \", evaluate_model(model, val, features)[0])\n",
    "    print(\"Evaluación TEST: \", evaluate_model(model, test, features)[0])\n",
    "   \n",
    "    # 7. Ejemplo: predecir 7 dias futuros usando los últimos datos del test set\n",
    "    last_block = pd.concat([train, val, test]).iloc[-180:].copy()  # usar ventana de referencia\n",
    "    preds_future = predict_future(model, last_block, features, horizon=7)\n",
    "    print(\"Predicciones próximos 7 dias:\")\n",
    "    print(preds_future.head(7))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ea094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
