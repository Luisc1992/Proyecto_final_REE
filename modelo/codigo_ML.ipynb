{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f983fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (2.0.43)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\david\\anaconda3\\envs\\mi_entorno\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy sqlalchemy psycopg2-binary scikit-learn lightgbm joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import timedelta\n",
    "\n",
    "#DB\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# ML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"proyectohabreee.cv4ea0syasip.eu-north-1.rds.amazonaws.com\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"postgres\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\", \"proyectohabree123\")\n",
    "TABLE_NAME = \"demanda_ree\"\n",
    "\n",
    "# Paths\n",
    "MODEL_PATH = \"lgb_demand_model.joblib\"\n",
    "FEATURES_PATH = \"features_cols.txt\"\n",
    "\n",
    "# ---------------------------\n",
    "# 1) EXTRAER DATOS\n",
    "# ---------------------------\n",
    "def load_data_from_rds(limit_rows=None, date_from=None, date_to=None):\n",
    "    \"\"\"\n",
    "    Conecta a la BBDD y devuelve un DataFrame con columnas: id, fecha, demanda_mw\n",
    "    Opcional: limit_rows para desarrollo local.\n",
    "    \"\"\"\n",
    "    conn_str = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "    engine = create_engine(conn_str, connect_args={\"connect_timeout\": 10})\n",
    "    query = f\"SELECT id, fecha, demanda_mw FROM {TABLE_NAME} ORDER BY fecha ASC\" \n",
    "    if limit_rows:\n",
    "        query += f\" LIMIT {limit_rows}\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741763e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 2) PREPROCESS / FEATURE ENGINEERING\n",
    "# ---------------------------\n",
    "def preprocess_and_features(df):\n",
    "    \"\"\"\n",
    "    - Convierte fecha a datetime y ordena.\n",
    "    - Crea features temporales y lags/rolling.\n",
    "    - Devuelve DataFrame listo para modelado.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['fecha'] = pd.to_datetime(df['fecha']).dt.date\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    df = df.sort_values('fecha').drop_duplicates(subset='fecha').reset_index(drop=True)\n",
    "          \n",
    "    # Features temporales\n",
    "    df['dayofweek'] = df['fecha'].dt.dayofweek\n",
    "    df['month'] = df['fecha'].dt.month\n",
    "    df['is_weekend'] = df['dayofweek'].isin([5,6]).astype(int)\n",
    "    \n",
    "    # Crea lags: 1, 7, 14, 30 (ayer, una semana antes, dos semanas antes, un mes antes)\n",
    "    lags = [1, 7, 14, 30]  # personalizable\n",
    "    for l in lags:\n",
    "        df[f'lag_{l}'] = df['demanda_mw'].shift(l)\n",
    "    \n",
    "    # rolling means\n",
    "    windows = [7, 14, 30]\n",
    "    for w in windows:\n",
    "        df[f'roll_mean_{w}'] = df['demanda_mw'].shift(1).rolling(window=w, min_periods=1).mean()\n",
    "        df[f'roll_std_{w}'] = df['demanda_mw'].shift(1).rolling(window=w, min_periods=1).std().fillna(0)\n",
    "    \n",
    "    # Drop initial rows with NaN from lags\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14eb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 3) TRAIN / VALIDATION SPLIT (temporal)\n",
    "# ---------------------------\n",
    "def temporal_train_test_split(df, val_size_days=500, test_size_days=500):\n",
    "    \"\"\"\n",
    "    Divide en train/val/test en orden temporal.\n",
    "    val_size_days, test_size_days: cuánto reservar para validación y test (en días).\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    if n < (val_size_days + test_size_days + 10):\n",
    "        raise ValueError(\"Muy pocos datos para dividir en train/val/test.\")\n",
    "\n",
    "    train_end = n - val_size_days - test_size_days\n",
    "    val_end = n - test_size_days\n",
    "\n",
    "    train = df.iloc[:train_end].copy()\n",
    "    val = df.iloc[train_end:val_end].copy()\n",
    "    test = df.iloc[val_end:].copy()\n",
    "    \n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695a638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 4) MODEL TRAIN\n",
    "# ---------------------------\n",
    "def train_lightgbm(train_df, val_df, features, target='demanda_mw', params=None):\n",
    "    train_data = lgb.Dataset(train_df[features], label=train_df[target])\n",
    "    val_data = lgb.Dataset(val_df[features], label=val_df[target])\n",
    "    default_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.005,\n",
    "        \"num_leaves\": 31,\n",
    "        \"n_estimators\": 1000,\n",
    "    }\n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "    gbm = lgb.train(default_params, \n",
    "                    train_data, \n",
    "                    valid_sets=[val_data],\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(stopping_rounds=50),\n",
    "                        lgb.log_evaluation(period=50)  # imprime cada 50 iteraciones\n",
    "                    ] \n",
    "    )\n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fbe77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 5) EVALUATION\n",
    "# ---------------------------\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, df, features, target='demanda_mw'):\n",
    "    preds = model.predict(df[features])\n",
    "    mae = mean_absolute_error(df[target], preds)\n",
    "    rmse = np.sqrt(mean_squared_error(df[target], preds))  # <- calculado manualmente\n",
    "    mape = np.mean(np.abs((df[target] - preds) / (df[target] + 1e-9))) * 100\n",
    "    accuracy = 100 - mape\n",
    "    return {\"MAE: \": mae, \"RMSE: \": rmse, \"MAPE(%): \": mape, \"ACC (%): \": accuracy}, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0977340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 6) PREDICT FUTURE (horizon steps)\n",
    "# ---------------------------\n",
    "def predict_future(model, last_df, features, horizon=7):\n",
    "    \"\"\"\n",
    "    last_df: DataFrame with the latest rows including features (must include fecha and demanda_mw).\n",
    "    Devuelve DataFrame con predicciones para next `horizon` steps (assume hourly).\n",
    "    Procedimiento: iterativo, se genera features usando predicción anterior para lags.\n",
    "    \"\"\"\n",
    "    last_df = last_df.copy().sort_values('fecha').reset_index(drop=True)\n",
    "    preds = []\n",
    "    df_work = last_df.copy()\n",
    "\n",
    "    for step in range(horizon):\n",
    "        next_time = df_work['fecha'].iloc[-1] + pd.Timedelta(days=1)\n",
    "        row = {\"fecha\": next_time}\n",
    "        row['dayofweek'] = next_time.dayofweek\n",
    "        row['month'] = next_time.month\n",
    "        row['is_weekend'] = int(next_time.dayofweek in [5,6])\n",
    "        \n",
    "        # lags: tomar de df_work\n",
    "        for l in [1,7,14,30]:\n",
    "            if l <= len(df_work):\n",
    "                row[f'lag_{l}'] = df_work['demanda_mw'].iloc[-l]\n",
    "            else:\n",
    "                row[f'lag_{l}'] = np.nan\n",
    "\n",
    "        # rolling means/std using last values\n",
    "        for w in [7,14,30]:\n",
    "            vals = df_work['demanda_mw'].shift(1).iloc[-w:] if len(df_work) >= 1 else []\n",
    "            if len(vals) > 0:\n",
    "                row[f'roll_mean_{w}'] = float(vals.mean())\n",
    "                row[f'roll_std_{w}'] = float(vals.std()) if len(vals) > 1 else 0.0\n",
    "            else:\n",
    "                row[f'roll_mean_{w}'] = np.nan\n",
    "                row[f'roll_std_{w}'] = np.nan\n",
    "        \n",
    "        row_df = pd.DataFrame([row])\n",
    "        # fill NaNs with reasonable values (e.g., mean of each column from df_work)\n",
    "        for c in features:\n",
    "            if c not in row_df.columns:\n",
    "                row_df[c] = np.nan\n",
    "        \n",
    "        # align columns\n",
    "        row_df = row_df[features].fillna(df_work[features].mean())\n",
    "        pred = model.predict(row_df)[0]\n",
    "        \n",
    "        # append\n",
    "        new_row = {\"fecha\": next_time, \"demanda_mw\": pred}\n",
    "        preds.append(new_row)\n",
    "        # add to df_work for next iteration\n",
    "        df_work = pd.concat([df_work, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    return pd.DataFrame(preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0efec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros extraídos: 5388\n",
      "Registros tras preprocess: 5358\n",
      "Tamaños -> train: 4358 val: 500 test: 500\n",
      "Columnas disponibles: ['id', 'fecha', 'demanda_mw', 'dayofweek', 'month', 'is_weekend', 'lag_1', 'lag_7', 'lag_14', 'lag_30', 'roll_mean_7', 'roll_std_7', 'roll_mean_14', 'roll_std_14', 'roll_mean_30', 'roll_std_30']\n",
      "Features seleccionadas: ['dayofweek', 'month', 'is_weekend', 'lag_1', 'lag_7', 'lag_14', 'lag_30', 'roll_mean_7', 'roll_std_7', 'roll_mean_14', 'roll_std_14', 'roll_mean_30', 'roll_std_30']\n",
      "Tamaño TRAIN: (4358, 16)\n",
      "Tamaño VAL: (500, 16)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's rmse: 64663.9\n",
      "[100]\tvalid_0's rmse: 54003.8\n",
      "[150]\tvalid_0's rmse: 46184.5\n",
      "[200]\tvalid_0's rmse: 40128.9\n",
      "[250]\tvalid_0's rmse: 35714.6\n",
      "[300]\tvalid_0's rmse: 32642.7\n",
      "[350]\tvalid_0's rmse: 30313.2\n",
      "[400]\tvalid_0's rmse: 28642\n",
      "[450]\tvalid_0's rmse: 27471.8\n",
      "[500]\tvalid_0's rmse: 26579.1\n",
      "[550]\tvalid_0's rmse: 25924.2\n",
      "[600]\tvalid_0's rmse: 25450.8\n",
      "[650]\tvalid_0's rmse: 25088.4\n",
      "[700]\tvalid_0's rmse: 24843.4\n",
      "[750]\tvalid_0's rmse: 24716.6\n",
      "[800]\tvalid_0's rmse: 24620\n",
      "[850]\tvalid_0's rmse: 24560.8\n",
      "[900]\tvalid_0's rmse: 24516.1\n",
      "[950]\tvalid_0's rmse: 24479.7\n",
      "[1000]\tvalid_0's rmse: 24442.7\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 24442.7\n",
      "Modelo guardado en: lgb_demand_model.joblib\n",
      "Evaluación TRAIN:  {'MAE: ': 10576.201665973917, 'RMSE: ': np.float64(16421.627165358677), 'MAPE(%): ': np.float64(1.5151277070561522), 'ACC (%): ': np.float64(98.48487229294385)}\n",
      "Evaluación VAL:  {'MAE: ': 16622.660484838514, 'RMSE: ': np.float64(24442.65941315215), 'MAPE(%): ': np.float64(2.537366254252644), 'ACC (%): ': np.float64(97.46263374574735)}\n",
      "Evaluación TEST:  {'MAE: ': 16648.784552437286, 'RMSE: ': np.float64(25083.12211034054), 'MAPE(%): ': np.float64(2.5053468339808913), 'ACC (%): ': np.float64(97.4946531660191)}\n",
      "Predicciones próximos 7 dias:\n",
      "       fecha     demanda_mw\n",
      "0 2025-10-01  695800.540894\n",
      "1 2025-10-02  680733.006428\n",
      "2 2025-10-03  650309.565993\n",
      "3 2025-10-04  595454.317765\n",
      "4 2025-10-05  653257.800853\n",
      "5 2025-10-06  658589.831129\n",
      "6 2025-10-07  649318.455130\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# MAIN FLOW\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # 1. Cargar\n",
    "    df = load_data_from_rds()\n",
    "    print(\"Registros extraídos:\", len(df))\n",
    "    \n",
    "    # 2. Preprocess\n",
    "    df_proc = preprocess_and_features(df)\n",
    "    print(\"Registros tras preprocess:\", len(df_proc))\n",
    "    \n",
    "    # 3. Split\n",
    "    train, val, test = temporal_train_test_split(df_proc)\n",
    "    print(\"Tamaños -> train:\", len(train), \"val:\", len(val), \"test:\", len(test))\n",
    "    \n",
    "    # 4. Features list\n",
    "    # Excluir columnas id, fecha, demanda_mw\n",
    "    excluded = ['id', 'fecha', 'demanda_mw']\n",
    "    features = [c for c in df_proc.columns if c not in excluded]\n",
    "\n",
    "    print(\"Columnas disponibles:\", df_proc.columns.tolist())\n",
    "    print(\"Features seleccionadas:\", features)\n",
    "    print(\"Tamaño TRAIN:\", train.shape)\n",
    "    print(\"Tamaño VAL:\", val.shape)\n",
    "    \n",
    "    # Guardar lista de features\n",
    "    with open(FEATURES_PATH, 'w') as f:\n",
    "        f.write(\"\\n\".join(features))\n",
    "    \n",
    "    # 5. Entrenar LightGBM\n",
    "    model = train_lightgbm(train, val, features)\n",
    "    \n",
    "    # guardar modelo\n",
    "    joblib.dump(model, MODEL_PATH)\n",
    "    print(\"Modelo guardado en:\", MODEL_PATH)\n",
    "    \n",
    "    # 6. Evaluar en train/val/test\n",
    "    print(\"Evaluación TRAIN: \", evaluate_model(model, train, features)[0])\n",
    "    print(\"Evaluación VAL: \", evaluate_model(model, val, features)[0])\n",
    "    print(\"Evaluación TEST: \", evaluate_model(model, test, features)[0])\n",
    "   \n",
    "    # 7. Ejemplo: predecir 7 dias futuros usando los últimos datos del test set\n",
    "    last_block = pd.concat([train, val, test]).iloc[-180:].copy()  # usar ventana de referencia\n",
    "    preds_future = predict_future(model, last_block, features, horizon=7)\n",
    "    print(\"Predicciones próximos 7 dias:\")\n",
    "    print(preds_future.head(7))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ea094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
